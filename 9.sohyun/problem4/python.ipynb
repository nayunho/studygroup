{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b98172-db21-42dd-a637-e2996bb4b4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\Lib\\site-packages\\matplotlib\\mpl-data\\matplotlibrc\n",
      "['C:\\\\Windows\\\\Fonts\\\\D2Coding']\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow.keras 이용\n",
    "# 32.챗봇_04_딥러닝모델 참고\n",
    "# 공부한 부분을 순서대로 참고하면서 이해하는 목적 \n",
    "# 모르면 답지도 같이 올려드리니 참고하세용~! \n",
    "# 빈 부분만 코드 작성하시면 됩니당\n",
    "\n",
    "# 오류와 한글처리\n",
    "import matplotlib as mpl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mpl.rcParams['font.family'] = 'C:\\\\Windows\\\\Fonts\\\\D2Coding'\n",
    "mpl.rcParams['font.size'] = 10\n",
    "\n",
    "print(mpl.matplotlib_fname())\n",
    "print(mpl.rcParams['font.family'])\n",
    "print(mpl.rcParams['font.size'])\n",
    "\n",
    "# 한글처리\n",
    "from matplotlib import rc, font_manager\n",
    "font_name = font_manager\\\n",
    "                .FontProperties(fname='C:\\\\WINDOWS\\\\Fonts\\\\gulim.ttc')\\\n",
    "                .get_name()\n",
    "rc('font', family=font_name)\n",
    "rc('axes', unicode_minus=False) # 음수값처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43cea7ed-36a5-4d7e-8723-834b72c0780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 엔진에 필요한 딥러닝 모델 사용하기\n",
    "# 케라스는 신경망모델 구축시 필요한 라이브러리이다(tensorflow 버전올라가면서 keras흡수)\n",
    "# MNIST 분류모델 학습\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "# 데이터 만들기\n",
    "# 1. 데이터 만들기\n",
    "# 1) MNIST 데이터셋을 로드하여 이미지 픽셀 데이터인 X_train과 X_test, 해당 이미지의 레이블(0~9 숫자) 값을 y_train과 y_test에 unpacking\n",
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e81fc3c-28c6-4fb6-9ee9-5fd143425707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 2) 이미지 픽셀 데이터(X_train과 X_test)를 0~255 범위에서 0~1 범위로 정규화\n",
    "X_train,X_test= X_train/255,X_test/255\n",
    "\n",
    "# 3) 정규화된 이미지 데이터 확인\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "912372f4-5df4-4044-a25d-4c97c573cf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n"
     ]
    }
   ],
   "source": [
    "# 4) tf.data를 이용해서 X_train과 y_train 데이터를 결합하고, 10000개의 배치크기로 셔플\n",
    "ds = tf.data.Dataset.from_tensor_slices((X_train,y_train)).shuffle(10000)\n",
    "\n",
    "\n",
    "# 5) 전체 학습 데이터의 70%를 실제 학습에 사용할 데이터 크기로 설정 = > 학습용 vs 검증용 = 7:3\n",
    "train_size =int(len(X_train)*0.7)\n",
    "\n",
    "# 6) 섞인 데이터셋에서 train_size만큼 데이터를 취하고, 배치 크기 20으로 설정 => 실제 학습에 사용될 데이터셋\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "\n",
    "# 7) 섞인 데이터셋에서 train_size만큼 건너뛰고, 나머지 데이터를 배치 크기 20으로 설정 => 검증에 사용될 데이터셋\n",
    "val_ds = ds.skip(train_size).batch(20)\n",
    "\n",
    "# 8) 실제 학습에 사용될 데이터의 크기를 출력\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b4d411-453a-429d-8d13-838443690be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# MNIST분류모델\n",
    "# 딥러닝 프로세스\n",
    "# 1. 모델정의\n",
    "# 1-1) 케라스의 Sequential(순차적) 모델을 생성\n",
    "model = Sequential() # 순차모델\n",
    "\n",
    "# 1-2) 입력 데이터의 형태를 28x28 크기의 2차원 배열에서 784(28x28)개의 1차원 배열로 평평하게 만듭니다\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "\n",
    "# 1-3) 20개의 노드를 가지며, 활성화 함수로 ReLU를 사용하는 은닉층 추가\n",
    "model.add(Dense(20,activation=\"relu\"))\n",
    "\n",
    "# 1-4) 10개의 노드를 가지며, 활성화 함수로 tanh를 사용하는 은닉층 추가\n",
    "model.add(Dense(10,activation=\"tanh\"))\n",
    "\n",
    "\n",
    "# 1-5) 10개의 노드(0~9 숫자 분류)를 가지며, 활성화 함수로 소프트맥스를 사용하는 출력층 추가\n",
    "model.add(Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d9627d-fe99-4254-af86-540e0d157926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델생성\n",
    "# 2-1) 손실 함수로 sparse_categorical_crossentropy를, 최적화 알고리즘으로 SGD를, 그리고 정확도(accuracy) metric을 사용하는 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c8c80a-7582-4ea3-9fe5-e8e550a92bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5157 - loss: 1.5742 - val_accuracy: 0.8633 - val_loss: 0.6127\n",
      "Epoch 2/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8730 - loss: 0.5475 - val_accuracy: 0.8934 - val_loss: 0.4169\n",
      "Epoch 3/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.3896 - val_accuracy: 0.9115 - val_loss: 0.3336\n",
      "Epoch 4/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.3292 - val_accuracy: 0.9194 - val_loss: 0.2987\n",
      "Epoch 5/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9230 - loss: 0.2858 - val_accuracy: 0.9264 - val_loss: 0.2670\n",
      "Epoch 6/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2599 - val_accuracy: 0.9306 - val_loss: 0.2446\n",
      "Epoch 7/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9364 - loss: 0.2351 - val_accuracy: 0.9332 - val_loss: 0.2311\n",
      "Epoch 8/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9399 - loss: 0.2203 - val_accuracy: 0.9382 - val_loss: 0.2190\n",
      "Epoch 9/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9419 - loss: 0.2065 - val_accuracy: 0.9438 - val_loss: 0.2018\n",
      "Epoch 10/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1913 - val_accuracy: 0.9442 - val_loss: 0.1970\n",
      "Epoch 11/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9489 - loss: 0.1854 - val_accuracy: 0.9456 - val_loss: 0.1914\n",
      "Epoch 12/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1758 - val_accuracy: 0.9469 - val_loss: 0.1868\n",
      "Epoch 13/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1663 - val_accuracy: 0.9494 - val_loss: 0.1769\n",
      "Epoch 14/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9556 - loss: 0.1601 - val_accuracy: 0.9503 - val_loss: 0.1736\n",
      "Epoch 15/15\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1535 - val_accuracy: 0.9509 - val_loss: 0.1720\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델학습\n",
    "# 3-1) train_ds를 학습 데이터로, val_ds를 검증 데이터로 사용하며, 15번의 epoch을 수행하여 모델 학습\n",
    "hist = model.fit(train_ds,validation_data=val_ds,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b358ea01-9781-4070-8766-c0eab4946610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.9407 - loss: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,700</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │          \u001b[38;5;34m15,700\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,022</span> (62.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,022\u001b[0m (62.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,020</span> (62.58 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,020\u001b[0m (62.58 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. 모델평가\n",
    "# 4-1) 테스트 데이터셋(X_test, y_test)에 대해 모델을 평가\n",
    "model.evaluate(X_test,y_test)\n",
    "\n",
    "# 4-2) 모델의 레이어 구조와 파라미터 수를 출력\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a357493-9e0a-47fe-9e48-4ea50dfa00f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 모델저장\n",
    "# 5-1) 학습된 모델을 './data/chatbot/mnist_model.keras' 파일로 저장\n",
    "\n",
    "model.save(\"./data/chatbot/mnist_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d12dd-59e2-428d-b8d2-52ee49bd214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 학습된 모델을 사용해서 예측하기\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 6-1) 저장된 모델을 로드\n",
    "model = load_model(\"./data/chatbot/mnist_model.keras\")\n",
    "\n",
    "# 6-2) 로드된 모델 확인\n",
    "model.summary()\n",
    "\n",
    "# 6-3) 로드된 모델을 테스트 데이터셋에 대해 평가하고, 자세한 출력(evaluate사용)\n",
    "model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "# 6-4) 테스트 데이터셋의 첫 번째 이미지를 그레이스케일로 시각화\n",
    "plt.imshow(X_test[0],cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# 7. 모델을 사용하여 img 인덱스에 해당하는 테스트 이미지를 분류\n",
    "# 7-1) np.argmax를 사용하여 가장 높은 확률을 가진 클래스 인덱스를 예측값으로 갖는다\n",
    "img = 100\n",
    "predict = np.argmax(model.predict(X_test[[img]]))\n",
    "\n",
    "# 7-2) 예측한 숫자를 출력\n",
    "print(f'손글씨 이미지의 예측한 숫자 = {predict}')\n",
    "\n",
    "# 결과분석\n",
    "# 예측을 잘 못하는 것을 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f8022-d547-4048-90c5-c37cb1d1e305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
